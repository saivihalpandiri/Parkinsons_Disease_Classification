{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e92bcf80-c121-4747-b15e-90fe3dbcaec0",
   "metadata": {},
   "source": [
    "### IMPORTING PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bd6e340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb4f7f4-fc3c-4139-a5d8-f4e496b7c547",
   "metadata": {},
   "source": [
    "### READING THE DATA SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e15dea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Parkinsson disease.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fa46d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phon_R01_S01_1</td>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phon_R01_S01_2</td>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phon_R01_S01_3</td>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phon_R01_S01_4</td>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phon_R01_S01_5</td>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>phon_R01_S50_2</td>\n",
       "      <td>174.188</td>\n",
       "      <td>230.978</td>\n",
       "      <td>94.261</td>\n",
       "      <td>0.00459</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00263</td>\n",
       "      <td>0.00259</td>\n",
       "      <td>0.00790</td>\n",
       "      <td>0.04087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07008</td>\n",
       "      <td>0.02764</td>\n",
       "      <td>19.517</td>\n",
       "      <td>0</td>\n",
       "      <td>0.448439</td>\n",
       "      <td>0.657899</td>\n",
       "      <td>-6.538586</td>\n",
       "      <td>0.121952</td>\n",
       "      <td>2.657476</td>\n",
       "      <td>0.133050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>phon_R01_S50_3</td>\n",
       "      <td>209.516</td>\n",
       "      <td>253.017</td>\n",
       "      <td>89.488</td>\n",
       "      <td>0.00564</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00331</td>\n",
       "      <td>0.00292</td>\n",
       "      <td>0.00994</td>\n",
       "      <td>0.02751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04812</td>\n",
       "      <td>0.01810</td>\n",
       "      <td>19.147</td>\n",
       "      <td>0</td>\n",
       "      <td>0.431674</td>\n",
       "      <td>0.683244</td>\n",
       "      <td>-6.195325</td>\n",
       "      <td>0.129303</td>\n",
       "      <td>2.784312</td>\n",
       "      <td>0.168895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>phon_R01_S50_4</td>\n",
       "      <td>174.688</td>\n",
       "      <td>240.005</td>\n",
       "      <td>74.287</td>\n",
       "      <td>0.01360</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00624</td>\n",
       "      <td>0.00564</td>\n",
       "      <td>0.01873</td>\n",
       "      <td>0.02308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03804</td>\n",
       "      <td>0.10715</td>\n",
       "      <td>17.883</td>\n",
       "      <td>0</td>\n",
       "      <td>0.407567</td>\n",
       "      <td>0.655683</td>\n",
       "      <td>-6.787197</td>\n",
       "      <td>0.158453</td>\n",
       "      <td>2.679772</td>\n",
       "      <td>0.131728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>phon_R01_S50_5</td>\n",
       "      <td>198.764</td>\n",
       "      <td>396.961</td>\n",
       "      <td>74.904</td>\n",
       "      <td>0.00740</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00390</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.02296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03794</td>\n",
       "      <td>0.07223</td>\n",
       "      <td>19.020</td>\n",
       "      <td>0</td>\n",
       "      <td>0.451221</td>\n",
       "      <td>0.643956</td>\n",
       "      <td>-6.744577</td>\n",
       "      <td>0.207454</td>\n",
       "      <td>2.138608</td>\n",
       "      <td>0.123306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>phon_R01_S50_6</td>\n",
       "      <td>214.289</td>\n",
       "      <td>260.277</td>\n",
       "      <td>77.973</td>\n",
       "      <td>0.00567</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00295</td>\n",
       "      <td>0.00317</td>\n",
       "      <td>0.00885</td>\n",
       "      <td>0.01884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03078</td>\n",
       "      <td>0.04398</td>\n",
       "      <td>21.209</td>\n",
       "      <td>0</td>\n",
       "      <td>0.462803</td>\n",
       "      <td>0.664357</td>\n",
       "      <td>-5.724056</td>\n",
       "      <td>0.190667</td>\n",
       "      <td>2.555477</td>\n",
       "      <td>0.148569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "0    phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
       "1    phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
       "2    phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
       "3    phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
       "4    phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
       "..              ...          ...           ...           ...             ...   \n",
       "190  phon_R01_S50_2      174.188       230.978        94.261         0.00459   \n",
       "191  phon_R01_S50_3      209.516       253.017        89.488         0.00564   \n",
       "192  phon_R01_S50_4      174.688       240.005        74.287         0.01360   \n",
       "193  phon_R01_S50_5      198.764       396.961        74.904         0.00740   \n",
       "194  phon_R01_S50_6      214.289       260.277        77.973         0.00567   \n",
       "\n",
       "     MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
       "0             0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
       "1             0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
       "2             0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
       "3             0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
       "4             0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
       "..                ...       ...       ...         ...           ...  ...   \n",
       "190           0.00003   0.00263   0.00259     0.00790       0.04087  ...   \n",
       "191           0.00003   0.00331   0.00292     0.00994       0.02751  ...   \n",
       "192           0.00008   0.00624   0.00564     0.01873       0.02308  ...   \n",
       "193           0.00004   0.00370   0.00390     0.01109       0.02296  ...   \n",
       "194           0.00003   0.00295   0.00317     0.00885       0.01884  ...   \n",
       "\n",
       "     Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
       "0        0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
       "1        0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
       "2        0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
       "3        0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
       "4        0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
       "..           ...      ...     ...     ...       ...       ...       ...   \n",
       "190      0.07008  0.02764  19.517       0  0.448439  0.657899 -6.538586   \n",
       "191      0.04812  0.01810  19.147       0  0.431674  0.683244 -6.195325   \n",
       "192      0.03804  0.10715  17.883       0  0.407567  0.655683 -6.787197   \n",
       "193      0.03794  0.07223  19.020       0  0.451221  0.643956 -6.744577   \n",
       "194      0.03078  0.04398  21.209       0  0.462803  0.664357 -5.724056   \n",
       "\n",
       "      spread2        D2       PPE  \n",
       "0    0.266482  2.301442  0.284654  \n",
       "1    0.335590  2.486855  0.368674  \n",
       "2    0.311173  2.342259  0.332634  \n",
       "3    0.334147  2.405554  0.368975  \n",
       "4    0.234513  2.332180  0.410335  \n",
       "..        ...       ...       ...  \n",
       "190  0.121952  2.657476  0.133050  \n",
       "191  0.129303  2.784312  0.168895  \n",
       "192  0.158453  2.679772  0.131728  \n",
       "193  0.207454  2.138608  0.123306  \n",
       "194  0.190667  2.555477  0.148569  \n",
       "\n",
       "[195 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01ebee30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 195 entries, 0 to 194\n",
      "Data columns (total 24 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   name              195 non-null    object \n",
      " 1   MDVP:Fo(Hz)       195 non-null    float64\n",
      " 2   MDVP:Fhi(Hz)      195 non-null    float64\n",
      " 3   MDVP:Flo(Hz)      195 non-null    float64\n",
      " 4   MDVP:Jitter(%)    195 non-null    float64\n",
      " 5   MDVP:Jitter(Abs)  195 non-null    float64\n",
      " 6   MDVP:RAP          195 non-null    float64\n",
      " 7   MDVP:PPQ          195 non-null    float64\n",
      " 8   Jitter:DDP        195 non-null    float64\n",
      " 9   MDVP:Shimmer      195 non-null    float64\n",
      " 10  MDVP:Shimmer(dB)  195 non-null    float64\n",
      " 11  Shimmer:APQ3      195 non-null    float64\n",
      " 12  Shimmer:APQ5      195 non-null    float64\n",
      " 13  MDVP:APQ          195 non-null    float64\n",
      " 14  Shimmer:DDA       195 non-null    float64\n",
      " 15  NHR               195 non-null    float64\n",
      " 16  HNR               195 non-null    float64\n",
      " 17  status            195 non-null    int64  \n",
      " 18  RPDE              195 non-null    float64\n",
      " 19  DFA               195 non-null    float64\n",
      " 20  spread1           195 non-null    float64\n",
      " 21  spread2           195 non-null    float64\n",
      " 22  D2                195 non-null    float64\n",
      " 23  PPE               195 non-null    float64\n",
      "dtypes: float64(22), int64(1), object(1)\n",
      "memory usage: 36.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ce0456d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>MDVP:Shimmer(dB)</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>154.228641</td>\n",
       "      <td>197.104918</td>\n",
       "      <td>116.324631</td>\n",
       "      <td>0.006220</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>0.009920</td>\n",
       "      <td>0.029709</td>\n",
       "      <td>0.282251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046993</td>\n",
       "      <td>0.024847</td>\n",
       "      <td>21.885974</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.498536</td>\n",
       "      <td>0.718099</td>\n",
       "      <td>-5.684397</td>\n",
       "      <td>0.226510</td>\n",
       "      <td>2.381826</td>\n",
       "      <td>0.206552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>41.390065</td>\n",
       "      <td>91.491548</td>\n",
       "      <td>43.521413</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>0.008903</td>\n",
       "      <td>0.018857</td>\n",
       "      <td>0.194877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030459</td>\n",
       "      <td>0.040418</td>\n",
       "      <td>4.425764</td>\n",
       "      <td>0.431878</td>\n",
       "      <td>0.103942</td>\n",
       "      <td>0.055336</td>\n",
       "      <td>1.090208</td>\n",
       "      <td>0.083406</td>\n",
       "      <td>0.382799</td>\n",
       "      <td>0.090119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>88.333000</td>\n",
       "      <td>102.145000</td>\n",
       "      <td>65.476000</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.009540</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013640</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>8.441000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256570</td>\n",
       "      <td>0.574282</td>\n",
       "      <td>-7.964984</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>1.423287</td>\n",
       "      <td>0.044539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>117.572000</td>\n",
       "      <td>134.862500</td>\n",
       "      <td>84.291000</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.004985</td>\n",
       "      <td>0.016505</td>\n",
       "      <td>0.148500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024735</td>\n",
       "      <td>0.005925</td>\n",
       "      <td>19.198000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.421306</td>\n",
       "      <td>0.674758</td>\n",
       "      <td>-6.450096</td>\n",
       "      <td>0.174351</td>\n",
       "      <td>2.099125</td>\n",
       "      <td>0.137451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>148.790000</td>\n",
       "      <td>175.829000</td>\n",
       "      <td>104.315000</td>\n",
       "      <td>0.004940</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.007490</td>\n",
       "      <td>0.022970</td>\n",
       "      <td>0.221000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038360</td>\n",
       "      <td>0.011660</td>\n",
       "      <td>22.085000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.495954</td>\n",
       "      <td>0.722254</td>\n",
       "      <td>-5.720868</td>\n",
       "      <td>0.218885</td>\n",
       "      <td>2.361532</td>\n",
       "      <td>0.194052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>182.769000</td>\n",
       "      <td>224.205500</td>\n",
       "      <td>140.018500</td>\n",
       "      <td>0.007365</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.003835</td>\n",
       "      <td>0.003955</td>\n",
       "      <td>0.011505</td>\n",
       "      <td>0.037885</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060795</td>\n",
       "      <td>0.025640</td>\n",
       "      <td>25.075500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.587562</td>\n",
       "      <td>0.761881</td>\n",
       "      <td>-5.046192</td>\n",
       "      <td>0.279234</td>\n",
       "      <td>2.636456</td>\n",
       "      <td>0.252980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>260.105000</td>\n",
       "      <td>592.030000</td>\n",
       "      <td>239.170000</td>\n",
       "      <td>0.033160</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.021440</td>\n",
       "      <td>0.019580</td>\n",
       "      <td>0.064330</td>\n",
       "      <td>0.119080</td>\n",
       "      <td>1.302000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169420</td>\n",
       "      <td>0.314820</td>\n",
       "      <td>33.047000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.685151</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-2.434031</td>\n",
       "      <td>0.450493</td>\n",
       "      <td>3.671155</td>\n",
       "      <td>0.527367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "count   195.000000    195.000000    195.000000      195.000000   \n",
       "mean    154.228641    197.104918    116.324631        0.006220   \n",
       "std      41.390065     91.491548     43.521413        0.004848   \n",
       "min      88.333000    102.145000     65.476000        0.001680   \n",
       "25%     117.572000    134.862500     84.291000        0.003460   \n",
       "50%     148.790000    175.829000    104.315000        0.004940   \n",
       "75%     182.769000    224.205500    140.018500        0.007365   \n",
       "max     260.105000    592.030000    239.170000        0.033160   \n",
       "\n",
       "       MDVP:Jitter(Abs)    MDVP:RAP    MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  \\\n",
       "count        195.000000  195.000000  195.000000  195.000000    195.000000   \n",
       "mean           0.000044    0.003306    0.003446    0.009920      0.029709   \n",
       "std            0.000035    0.002968    0.002759    0.008903      0.018857   \n",
       "min            0.000007    0.000680    0.000920    0.002040      0.009540   \n",
       "25%            0.000020    0.001660    0.001860    0.004985      0.016505   \n",
       "50%            0.000030    0.002500    0.002690    0.007490      0.022970   \n",
       "75%            0.000060    0.003835    0.003955    0.011505      0.037885   \n",
       "max            0.000260    0.021440    0.019580    0.064330      0.119080   \n",
       "\n",
       "       MDVP:Shimmer(dB)  ...  Shimmer:DDA         NHR         HNR      status  \\\n",
       "count        195.000000  ...   195.000000  195.000000  195.000000  195.000000   \n",
       "mean           0.282251  ...     0.046993    0.024847   21.885974    0.753846   \n",
       "std            0.194877  ...     0.030459    0.040418    4.425764    0.431878   \n",
       "min            0.085000  ...     0.013640    0.000650    8.441000    0.000000   \n",
       "25%            0.148500  ...     0.024735    0.005925   19.198000    1.000000   \n",
       "50%            0.221000  ...     0.038360    0.011660   22.085000    1.000000   \n",
       "75%            0.350000  ...     0.060795    0.025640   25.075500    1.000000   \n",
       "max            1.302000  ...     0.169420    0.314820   33.047000    1.000000   \n",
       "\n",
       "             RPDE         DFA     spread1     spread2          D2         PPE  \n",
       "count  195.000000  195.000000  195.000000  195.000000  195.000000  195.000000  \n",
       "mean     0.498536    0.718099   -5.684397    0.226510    2.381826    0.206552  \n",
       "std      0.103942    0.055336    1.090208    0.083406    0.382799    0.090119  \n",
       "min      0.256570    0.574282   -7.964984    0.006274    1.423287    0.044539  \n",
       "25%      0.421306    0.674758   -6.450096    0.174351    2.099125    0.137451  \n",
       "50%      0.495954    0.722254   -5.720868    0.218885    2.361532    0.194052  \n",
       "75%      0.587562    0.761881   -5.046192    0.279234    2.636456    0.252980  \n",
       "max      0.685151    0.825288   -2.434031    0.450493    3.671155    0.527367  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b51af07-f731-4bce-8362-3ed2040bf108",
   "metadata": {},
   "source": [
    "### CHECKING FOR THE NULL VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99e69603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                0\n",
       "MDVP:Fo(Hz)         0\n",
       "MDVP:Fhi(Hz)        0\n",
       "MDVP:Flo(Hz)        0\n",
       "MDVP:Jitter(%)      0\n",
       "MDVP:Jitter(Abs)    0\n",
       "MDVP:RAP            0\n",
       "MDVP:PPQ            0\n",
       "Jitter:DDP          0\n",
       "MDVP:Shimmer        0\n",
       "MDVP:Shimmer(dB)    0\n",
       "Shimmer:APQ3        0\n",
       "Shimmer:APQ5        0\n",
       "MDVP:APQ            0\n",
       "Shimmer:DDA         0\n",
       "NHR                 0\n",
       "HNR                 0\n",
       "status              0\n",
       "RPDE                0\n",
       "DFA                 0\n",
       "spread1             0\n",
       "spread2             0\n",
       "D2                  0\n",
       "PPE                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa5456a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "396a4c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)', 'MDVP:Flo(Hz)', 'MDVP:Jitter(%)',\n",
       "       'MDVP:Jitter(Abs)', 'MDVP:RAP', 'MDVP:PPQ', 'Jitter:DDP',\n",
       "       'MDVP:Shimmer', 'MDVP:Shimmer(dB)', 'Shimmer:APQ3', 'Shimmer:APQ5',\n",
       "       'MDVP:APQ', 'Shimmer:DDA', 'NHR', 'HNR', 'status', 'RPDE', 'DFA',\n",
       "       'spread1', 'spread2', 'D2', 'PPE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1036063d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phon_R01_S01_1</td>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phon_R01_S01_2</td>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phon_R01_S01_3</td>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phon_R01_S01_4</td>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phon_R01_S01_5</td>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "0  phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
       "1  phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
       "2  phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
       "3  phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
       "4  phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
       "\n",
       "   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
       "0           0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
       "1           0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
       "2           0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
       "3           0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
       "4           0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
       "\n",
       "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
       "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
       "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
       "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
       "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
       "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
       "\n",
       "    spread2        D2       PPE  \n",
       "0  0.266482  2.301442  0.284654  \n",
       "1  0.335590  2.486855  0.368674  \n",
       "2  0.311173  2.342259  0.332634  \n",
       "3  0.334147  2.405554  0.368975  \n",
       "4  0.234513  2.332180  0.410335  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55d7f776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "1    147\n",
       "0     48\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f908add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 24)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a7e2376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                195\n",
       "MDVP:Fo(Hz)         195\n",
       "MDVP:Fhi(Hz)        195\n",
       "MDVP:Flo(Hz)        195\n",
       "MDVP:Jitter(%)      173\n",
       "MDVP:Jitter(Abs)     19\n",
       "MDVP:RAP            155\n",
       "MDVP:PPQ            165\n",
       "Jitter:DDP          180\n",
       "MDVP:Shimmer        188\n",
       "MDVP:Shimmer(dB)    149\n",
       "Shimmer:APQ3        184\n",
       "Shimmer:APQ5        189\n",
       "MDVP:APQ            189\n",
       "Shimmer:DDA         189\n",
       "NHR                 185\n",
       "HNR                 195\n",
       "status                2\n",
       "RPDE                195\n",
       "DFA                 195\n",
       "spread1             195\n",
       "spread2             194\n",
       "D2                  195\n",
       "PPE                 195\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d308e039",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81215052-90bc-4c7f-8af4-674a0de5e458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>MDVP:Shimmer(dB)</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>0.426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>0.626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  MDVP:Jitter(Abs)  \\\n",
       "0      119.992       157.302        74.997         0.00784           0.00007   \n",
       "1      122.400       148.650       113.819         0.00968           0.00008   \n",
       "\n",
       "   MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  MDVP:Shimmer(dB)  ...  \\\n",
       "0   0.00370   0.00554     0.01109       0.04374             0.426  ...   \n",
       "1   0.00465   0.00696     0.01394       0.06134             0.626  ...   \n",
       "\n",
       "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
       "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
       "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
       "\n",
       "    spread2        D2       PPE  \n",
       "0  0.266482  2.301442  0.284654  \n",
       "1  0.335590  2.486855  0.368674  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51475239-e44f-46f0-a57d-52437cef057c",
   "metadata": {},
   "source": [
    "### IMPORTING OVERSAMPLING AND UNDERSAMPLING PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ff54bfc-4ba8-479d-a450-8cf928d06eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler,TomekLinks\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a17499f-300a-4f72-a4ba-f772ac724564",
   "metadata": {},
   "source": [
    "### IMPORTING CLASSIFICATION PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d1ef538-31df-4d65-8081-4f0f3289d18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cfee916-09d2-4280-b390-0b758ac6b25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 147, 0: 48})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df[\"status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99096aa4-9965-49b7-ad44-ec9f3d2853d2",
   "metadata": {},
   "source": [
    "### TRAINING THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5741a3f0-bf93-4fdb-83cf-44dc35f28cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(df.drop(columns=[\"status\"]),df[[\"status\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ff5fbe1-0943-45a1-ad39-2e964213b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "rus= RandomUnderSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a266dbe0-82ad-4c31-83ca-3accb75af140",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_rs,y_train_rs= rus.fit_resample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b8f9700-c8ed-46f3-8c32-099073f4066a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 109, 0: 37})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train_rs[\"status\"])\n",
    "Counter(y_train[\"status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41e1cd7c-dc72-4871-8fb7-10420fd29629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.55      0.67        11\n",
      "           1       0.88      0.97      0.93        38\n",
      "\n",
      "    accuracy                           0.88        49\n",
      "   macro avg       0.87      0.76      0.80        49\n",
      "weighted avg       0.88      0.88      0.87        49\n",
      "\n",
      "0.8775510204081632\n",
      "----------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.36      0.50        11\n",
      "           1       0.84      0.97      0.90        38\n",
      "\n",
      "    accuracy                           0.84        49\n",
      "   macro avg       0.82      0.67      0.70        49\n",
      "weighted avg       0.83      0.84      0.81        49\n",
      "\n",
      "0.8775510204081632\n"
     ]
    }
   ],
   "source": [
    "model=LogisticRegression()\n",
    "model.fit(x_train,y_train)\n",
    "Pred=model.predict(x_test)\n",
    "print(classification_report(y_test,Pred))\n",
    "print(accuracy_score(y_test,Pred))\n",
    "\n",
    "print(\"-----\"*20)\n",
    "\n",
    "model1=SVC()\n",
    "model1.fit(x_train_rs,y_train_rs)\n",
    "Pred_rs=model1.predict(x_test)\n",
    "print(classification_report(y_test,Pred_rs))\n",
    "print(accuracy_score(y_test,Pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fdd0da-05ec-4449-a663-7d127ddae69d",
   "metadata": {},
   "source": [
    "### PERFORMING OVER SAMPLING TECHNQUIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bf71e6b-f7c2-49e9-84b5-7667a2a343ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "to=TomekLinks()\n",
    "ro=RandomOverSampler()\n",
    "sm=SMOTE(k_neighbors=5)\n",
    "ada=ADASYN(n_neighbors=5)\n",
    "smo=SMOTEENN()\n",
    "smot=SMOTETomek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1fb72b7-d8c0-403c-bd63-84b6f3ed440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_rs1,y_train_rs1= to.fit_resample(x_train,y_train)\n",
    "x_train_rs2,y_train_rs2= ro.fit_resample(x_train,y_train)\n",
    "x_train_rs3,y_train_rs3= sm.fit_resample(x_train,y_train)\n",
    "x_train_rs4,y_train_rs4= ada.fit_resample(x_train,y_train)\n",
    "x_train_rs5,y_train_rs5= smo.fit_resample(x_train,y_train)\n",
    "x_train_rs6,y_train_rs6= smot.fit_resample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfe783be-a8b3-42d6-8170-31f3d7b9733e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 103, 0: 103})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train_rs1[\"status\"])\n",
    "Counter(y_train_rs2[\"status\"])\n",
    "Counter(y_train_rs3[\"status\"])\n",
    "Counter(y_train_rs4[\"status\"])\n",
    "Counter(y_train_rs5[\"status\"])\n",
    "Counter(y_train_rs6[\"status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72b802c6-e318-42e7-a627-cd54eb3180a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 109, 0: 37})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train[\"status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f845ad8b-ba6f-4dc4-bb6e-f5f045e3bb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=[LogisticRegression(),DecisionTreeClassifier(criterion='gini',max_depth=20,min_samples_split=5,random_state=24),RandomForestClassifier(n_estimators=20),BaggingClassifier(n_estimators=20,max_samples=0.8,max_features=1),SVC(kernel='linear',verbose=1),GaussianNB()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efff5c74-f1e2-46a3-854c-c68298c23894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.82      0.58        11\n",
      "           1       0.93      0.71      0.81        38\n",
      "\n",
      "    accuracy                           0.73        49\n",
      "   macro avg       0.69      0.76      0.69        49\n",
      "weighted avg       0.82      0.73      0.76        49\n",
      "\n",
      "0.7346938775510204\n",
      "DecisionTreeClassifier(max_depth=20, min_samples_split=5, random_state=24)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.91      0.59        11\n",
      "           1       0.96      0.66      0.78        38\n",
      "\n",
      "    accuracy                           0.71        49\n",
      "   macro avg       0.70      0.78      0.68        49\n",
      "weighted avg       0.84      0.71      0.74        49\n",
      "\n",
      "0.7142857142857143\n",
      "RandomForestClassifier(n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.82      0.62        11\n",
      "           1       0.94      0.76      0.84        38\n",
      "\n",
      "    accuracy                           0.78        49\n",
      "   macro avg       0.72      0.79      0.73        49\n",
      "weighted avg       0.84      0.78      0.79        49\n",
      "\n",
      "0.7755102040816326\n",
      "BaggingClassifier(max_features=1, max_samples=0.8, n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.82      0.55        11\n",
      "           1       0.93      0.66      0.77        38\n",
      "\n",
      "    accuracy                           0.69        49\n",
      "   macro avg       0.67      0.74      0.66        49\n",
      "weighted avg       0.81      0.69      0.72        49\n",
      "\n",
      "0.6938775510204082\n",
      "SVC(kernel='linear', verbose=1)\n",
      "[LibSVM]              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.82      0.60        11\n",
      "           1       0.93      0.74      0.82        38\n",
      "\n",
      "    accuracy                           0.76        49\n",
      "   macro avg       0.70      0.78      0.71        49\n",
      "weighted avg       0.83      0.76      0.77        49\n",
      "\n",
      "0.7551020408163265\n",
      "GaussianNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.91      0.56        11\n",
      "           1       0.96      0.61      0.74        38\n",
      "\n",
      "    accuracy                           0.67        49\n",
      "   macro avg       0.68      0.76      0.65        49\n",
      "weighted avg       0.83      0.67      0.70        49\n",
      "\n",
      "0.673469387755102\n"
     ]
    }
   ],
   "source": [
    "for i in model:\n",
    "    print(i)\n",
    "    i.fit(x_train_rs,y_train_rs)\n",
    "    Pred=i.predict(x_test)\n",
    "    print(classification_report(y_test,Pred))\n",
    "    print(accuracy_score(y_test,Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3780fb9e-025e-4978-9036-972116e50595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.55      0.67        11\n",
      "           1       0.88      0.97      0.93        38\n",
      "\n",
      "    accuracy                           0.88        49\n",
      "   macro avg       0.87      0.76      0.80        49\n",
      "weighted avg       0.88      0.88      0.87        49\n",
      "\n",
      "0.8775510204081632\n",
      "DecisionTreeClassifier(max_depth=20, min_samples_split=5, random_state=24)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.73      0.67        11\n",
      "           1       0.92      0.87      0.89        38\n",
      "\n",
      "    accuracy                           0.84        49\n",
      "   macro avg       0.77      0.80      0.78        49\n",
      "weighted avg       0.85      0.84      0.84        49\n",
      "\n",
      "0.8367346938775511\n",
      "RandomForestClassifier(n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        11\n",
      "           1       0.97      0.97      0.97        38\n",
      "\n",
      "    accuracy                           0.96        49\n",
      "   macro avg       0.94      0.94      0.94        49\n",
      "weighted avg       0.96      0.96      0.96        49\n",
      "\n",
      "0.9591836734693877\n",
      "BaggingClassifier(max_features=1, max_samples=0.8, n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.36      0.44        11\n",
      "           1       0.83      0.92      0.88        38\n",
      "\n",
      "    accuracy                           0.80        49\n",
      "   macro avg       0.70      0.64      0.66        49\n",
      "weighted avg       0.77      0.80      0.78        49\n",
      "\n",
      "0.7959183673469388\n",
      "SVC(kernel='linear', verbose=1)\n",
      "[LibSVM]              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.55      0.71        11\n",
      "           1       0.88      1.00      0.94        38\n",
      "\n",
      "    accuracy                           0.90        49\n",
      "   macro avg       0.94      0.77      0.82        49\n",
      "weighted avg       0.91      0.90      0.89        49\n",
      "\n",
      "0.8979591836734694\n",
      "GaussianNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.91      0.54        11\n",
      "           1       0.96      0.58      0.72        38\n",
      "\n",
      "    accuracy                           0.65        49\n",
      "   macro avg       0.67      0.74      0.63        49\n",
      "weighted avg       0.83      0.65      0.68        49\n",
      "\n",
      "0.6530612244897959\n"
     ]
    }
   ],
   "source": [
    "for i in model:\n",
    "    print(i)\n",
    "    i.fit(x_train_rs1,y_train_rs1)\n",
    "    Pred=i.predict(x_test)\n",
    "    print(classification_report(y_test,Pred))\n",
    "    print(accuracy_score(y_test,Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78404611-7787-4cd1-b148-e46aadda392d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.82      0.64        11\n",
      "           1       0.94      0.79      0.86        38\n",
      "\n",
      "    accuracy                           0.80        49\n",
      "   macro avg       0.73      0.80      0.75        49\n",
      "weighted avg       0.85      0.80      0.81        49\n",
      "\n",
      "0.7959183673469388\n",
      "DecisionTreeClassifier(max_depth=20, min_samples_split=5, random_state=24)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.73      0.59        11\n",
      "           1       0.91      0.79      0.85        38\n",
      "\n",
      "    accuracy                           0.78        49\n",
      "   macro avg       0.70      0.76      0.72        49\n",
      "weighted avg       0.82      0.78      0.79        49\n",
      "\n",
      "0.7755102040816326\n",
      "RandomForestClassifier(n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        11\n",
      "           1       0.97      0.97      0.97        38\n",
      "\n",
      "    accuracy                           0.96        49\n",
      "   macro avg       0.94      0.94      0.94        49\n",
      "weighted avg       0.96      0.96      0.96        49\n",
      "\n",
      "0.9591836734693877\n",
      "BaggingClassifier(max_features=1, max_samples=0.8, n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64        11\n",
      "           1       0.89      0.89      0.89        38\n",
      "\n",
      "    accuracy                           0.84        49\n",
      "   macro avg       0.77      0.77      0.77        49\n",
      "weighted avg       0.84      0.84      0.84        49\n",
      "\n",
      "0.8367346938775511\n",
      "SVC(kernel='linear', verbose=1)\n",
      "[LibSVM]              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.91      0.61        11\n",
      "           1       0.96      0.68      0.80        38\n",
      "\n",
      "    accuracy                           0.73        49\n",
      "   macro avg       0.71      0.80      0.70        49\n",
      "weighted avg       0.85      0.73      0.76        49\n",
      "\n",
      "0.7346938775510204\n",
      "GaussianNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.91      0.54        11\n",
      "           1       0.96      0.58      0.72        38\n",
      "\n",
      "    accuracy                           0.65        49\n",
      "   macro avg       0.67      0.74      0.63        49\n",
      "weighted avg       0.83      0.65      0.68        49\n",
      "\n",
      "0.6530612244897959\n"
     ]
    }
   ],
   "source": [
    "for i in model:\n",
    "    print(i)\n",
    "    i.fit(x_train_rs2,y_train_rs2)\n",
    "    Pred=i.predict(x_test)\n",
    "    print(classification_report(y_test,Pred))\n",
    "    print(accuracy_score(y_test,Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05713d59-f053-42bc-9add-afd0bc77a7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.82      0.60        11\n",
      "           1       0.93      0.74      0.82        38\n",
      "\n",
      "    accuracy                           0.76        49\n",
      "   macro avg       0.70      0.78      0.71        49\n",
      "weighted avg       0.83      0.76      0.77        49\n",
      "\n",
      "0.7551020408163265\n",
      "DecisionTreeClassifier(max_depth=20, min_samples_split=5, random_state=24)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.91      0.80        11\n",
      "           1       0.97      0.89      0.93        38\n",
      "\n",
      "    accuracy                           0.90        49\n",
      "   macro avg       0.84      0.90      0.87        49\n",
      "weighted avg       0.91      0.90      0.90        49\n",
      "\n",
      "0.8979591836734694\n",
      "RandomForestClassifier(n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87        11\n",
      "           1       0.97      0.95      0.96        38\n",
      "\n",
      "    accuracy                           0.94        49\n",
      "   macro avg       0.90      0.93      0.91        49\n",
      "weighted avg       0.94      0.94      0.94        49\n",
      "\n",
      "0.9387755102040817\n",
      "BaggingClassifier(max_features=1, max_samples=0.8, n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.91      0.51        11\n",
      "           1       0.95      0.53      0.68        38\n",
      "\n",
      "    accuracy                           0.61        49\n",
      "   macro avg       0.65      0.72      0.60        49\n",
      "weighted avg       0.82      0.61      0.64        49\n",
      "\n",
      "0.6122448979591837\n",
      "SVC(kernel='linear', verbose=1)\n",
      "[LibSVM]              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.82      0.60        11\n",
      "           1       0.93      0.74      0.82        38\n",
      "\n",
      "    accuracy                           0.76        49\n",
      "   macro avg       0.70      0.78      0.71        49\n",
      "weighted avg       0.83      0.76      0.77        49\n",
      "\n",
      "0.7551020408163265\n",
      "GaussianNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.91      0.54        11\n",
      "           1       0.96      0.58      0.72        38\n",
      "\n",
      "    accuracy                           0.65        49\n",
      "   macro avg       0.67      0.74      0.63        49\n",
      "weighted avg       0.83      0.65      0.68        49\n",
      "\n",
      "0.6530612244897959\n"
     ]
    }
   ],
   "source": [
    "for i in model:\n",
    "    print(i)\n",
    "    i.fit(x_train_rs3,y_train_rs3)\n",
    "    Pred=i.predict(x_test)\n",
    "    print(classification_report(y_test,Pred))\n",
    "    print(accuracy_score(y_test,Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57086e57-590b-4d92-9e1b-1b6d9c186534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69        11\n",
      "           1       1.00      0.74      0.85        38\n",
      "\n",
      "    accuracy                           0.80        49\n",
      "   macro avg       0.76      0.87      0.77        49\n",
      "weighted avg       0.89      0.80      0.81        49\n",
      "\n",
      "0.7959183673469388\n",
      "DecisionTreeClassifier(max_depth=20, min_samples_split=5, random_state=24)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76        11\n",
      "           1       0.92      0.95      0.94        38\n",
      "\n",
      "    accuracy                           0.90        49\n",
      "   macro avg       0.86      0.84      0.85        49\n",
      "weighted avg       0.90      0.90      0.90        49\n",
      "\n",
      "0.8979591836734694\n",
      "RandomForestClassifier(n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.83        11\n",
      "           1       0.97      0.92      0.95        38\n",
      "\n",
      "    accuracy                           0.92        49\n",
      "   macro avg       0.87      0.92      0.89        49\n",
      "weighted avg       0.93      0.92      0.92        49\n",
      "\n",
      "0.9183673469387755\n",
      "BaggingClassifier(max_features=1, max_samples=0.8, n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.91      0.61        11\n",
      "           1       0.96      0.68      0.80        38\n",
      "\n",
      "    accuracy                           0.73        49\n",
      "   macro avg       0.71      0.80      0.70        49\n",
      "weighted avg       0.85      0.73      0.76        49\n",
      "\n",
      "0.7346938775510204\n",
      "SVC(kernel='linear', verbose=1)\n",
      "[LibSVM]              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      1.00      0.65        11\n",
      "           1       1.00      0.68      0.81        38\n",
      "\n",
      "    accuracy                           0.76        49\n",
      "   macro avg       0.74      0.84      0.73        49\n",
      "weighted avg       0.88      0.76      0.78        49\n",
      "\n",
      "0.7551020408163265\n",
      "GaussianNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.91      0.53        11\n",
      "           1       0.95      0.55      0.70        38\n",
      "\n",
      "    accuracy                           0.63        49\n",
      "   macro avg       0.66      0.73      0.61        49\n",
      "weighted avg       0.82      0.63      0.66        49\n",
      "\n",
      "0.6326530612244898\n"
     ]
    }
   ],
   "source": [
    "for i in model:\n",
    "    print(i)\n",
    "    i.fit(x_train_rs4,y_train_rs4)\n",
    "    Pred=i.predict(x_test)\n",
    "    print(classification_report(y_test,Pred))\n",
    "    print(accuracy_score(y_test,Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e8012d1-8a64-4968-b46f-4132e391b065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.64      0.50        11\n",
      "           1       0.88      0.74      0.80        38\n",
      "\n",
      "    accuracy                           0.71        49\n",
      "   macro avg       0.64      0.69      0.65        49\n",
      "weighted avg       0.77      0.71      0.73        49\n",
      "\n",
      "0.7142857142857143\n",
      "DecisionTreeClassifier(max_depth=20, min_samples_split=5, random_state=24)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.82      0.75        11\n",
      "           1       0.94      0.89      0.92        38\n",
      "\n",
      "    accuracy                           0.88        49\n",
      "   macro avg       0.82      0.86      0.83        49\n",
      "weighted avg       0.89      0.88      0.88        49\n",
      "\n",
      "0.8775510204081632\n",
      "RandomForestClassifier(n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87        11\n",
      "           1       0.97      0.95      0.96        38\n",
      "\n",
      "    accuracy                           0.94        49\n",
      "   macro avg       0.90      0.93      0.91        49\n",
      "weighted avg       0.94      0.94      0.94        49\n",
      "\n",
      "0.9387755102040817\n",
      "BaggingClassifier(max_features=1, max_samples=0.8, n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.91      0.69        11\n",
      "           1       0.97      0.79      0.87        38\n",
      "\n",
      "    accuracy                           0.82        49\n",
      "   macro avg       0.76      0.85      0.78        49\n",
      "weighted avg       0.88      0.82      0.83        49\n",
      "\n",
      "0.8163265306122449\n",
      "SVC(kernel='linear', verbose=1)\n",
      "[LibSVM]              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.91      0.67        11\n",
      "           1       0.97      0.76      0.85        38\n",
      "\n",
      "    accuracy                           0.80        49\n",
      "   macro avg       0.75      0.84      0.76        49\n",
      "weighted avg       0.87      0.80      0.81        49\n",
      "\n",
      "0.7959183673469388\n",
      "GaussianNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.91      0.54        11\n",
      "           1       0.96      0.58      0.72        38\n",
      "\n",
      "    accuracy                           0.65        49\n",
      "   macro avg       0.67      0.74      0.63        49\n",
      "weighted avg       0.83      0.65      0.68        49\n",
      "\n",
      "0.6530612244897959\n"
     ]
    }
   ],
   "source": [
    "for i in model:\n",
    "    print(i)\n",
    "    i.fit(x_train_rs5,y_train_rs5)\n",
    "    Pred=i.predict(x_test)\n",
    "    print(classification_report(y_test,Pred))\n",
    "    print(accuracy_score(y_test,Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8c65fe7-c75f-41f6-a7a9-58c0102895f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.82      0.67        11\n",
      "           1       0.94      0.82      0.87        38\n",
      "\n",
      "    accuracy                           0.82        49\n",
      "   macro avg       0.75      0.82      0.77        49\n",
      "weighted avg       0.85      0.82      0.83        49\n",
      "\n",
      "0.8163265306122449\n",
      "DecisionTreeClassifier(max_depth=20, min_samples_split=5, random_state=24)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.82      0.69        11\n",
      "           1       0.94      0.84      0.89        38\n",
      "\n",
      "    accuracy                           0.84        49\n",
      "   macro avg       0.77      0.83      0.79        49\n",
      "weighted avg       0.86      0.84      0.84        49\n",
      "\n",
      "0.8367346938775511\n",
      "RandomForestClassifier(n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        11\n",
      "           1       0.97      0.97      0.97        38\n",
      "\n",
      "    accuracy                           0.96        49\n",
      "   macro avg       0.94      0.94      0.94        49\n",
      "weighted avg       0.96      0.96      0.96        49\n",
      "\n",
      "0.9591836734693877\n",
      "BaggingClassifier(max_features=1, max_samples=0.8, n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.91      0.71        11\n",
      "           1       0.97      0.82      0.89        38\n",
      "\n",
      "    accuracy                           0.84        49\n",
      "   macro avg       0.78      0.86      0.80        49\n",
      "weighted avg       0.88      0.84      0.85        49\n",
      "\n",
      "0.8367346938775511\n",
      "SVC(kernel='linear', verbose=1)\n",
      "[LibSVM]              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.82      0.67        11\n",
      "           1       0.94      0.82      0.87        38\n",
      "\n",
      "    accuracy                           0.82        49\n",
      "   macro avg       0.75      0.82      0.77        49\n",
      "weighted avg       0.85      0.82      0.83        49\n",
      "\n",
      "0.8163265306122449\n",
      "GaussianNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.91      0.57        11\n",
      "           1       0.96      0.63      0.76        38\n",
      "\n",
      "    accuracy                           0.69        49\n",
      "   macro avg       0.69      0.77      0.67        49\n",
      "weighted avg       0.84      0.69      0.72        49\n",
      "\n",
      "0.6938775510204082\n"
     ]
    }
   ],
   "source": [
    "for i in model:\n",
    "    print(i)\n",
    "    i.fit(x_train_rs6,y_train_rs6)\n",
    "    Pred=i.predict(x_test)\n",
    "    print(classification_report(y_test,Pred))\n",
    "    print(accuracy_score(y_test,Pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f027b8-578e-4dc4-a0bd-243aafcf37ce",
   "metadata": {},
   "source": [
    "### ROC AND AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ca567b9-5604-4033-a7a7-a7dbafdfde25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b9489c-eb09-4244-abc0-1ca5e39b5194",
   "metadata": {},
   "source": [
    "### WE CHOOSEN LOGISTIC,BAGGING AND SVC BECAUSE IT HAD HIGH ACCURACY SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b66cd3a0-4e6e-4f66-b068-bb328cd5c9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [\n",
    "     LogisticRegression(),\n",
    "     BaggingClassifier(n_estimators=100,max_features=0.8,max_samples=0.6),\n",
    "    SVC(probability=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "887613bb-82b5-407a-bd64-7a5b7540c1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "for i in model:\n",
    "    i.fit(x_train,y_train)\n",
    "    yp_prob = i.predict_proba(x_test)[:,1]\n",
    "    fpr,tpr,_ = roc_curve(y_test,yp_prob)\n",
    "    area = auc(fpr,tpr)\n",
    "    plt.plot(fpr,tpr,label = f'auc of {i}: {area: .2f}')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1673a73-d33a-47c6-8426-dc317219f0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
